{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import re as re"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using stopwords function to remove unwanted text from sentence  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i\n",
      "me\n",
      "my\n",
      "myself\n",
      "we\n",
      "our\n",
      "ours\n",
      "ourselves\n",
      "you\n",
      "you're\n",
      "you've\n",
      "you'll\n",
      "you'd\n",
      "your\n",
      "yours\n",
      "yourself\n",
      "yourselves\n",
      "he\n",
      "him\n",
      "his\n",
      "himself\n",
      "she\n",
      "she's\n",
      "her\n",
      "hers\n",
      "herself\n",
      "it\n",
      "it's\n",
      "its\n",
      "itself\n",
      "they\n",
      "them\n",
      "their\n",
      "theirs\n",
      "themselves\n",
      "what\n",
      "which\n",
      "who\n",
      "whom\n",
      "this\n",
      "that\n",
      "that'll\n",
      "these\n",
      "those\n",
      "am\n",
      "is\n",
      "are\n",
      "was\n",
      "were\n",
      "be\n",
      "been\n",
      "being\n",
      "have\n",
      "has\n",
      "had\n",
      "having\n",
      "do\n",
      "does\n",
      "did\n",
      "doing\n",
      "a\n",
      "an\n",
      "the\n",
      "and\n",
      "but\n",
      "if\n",
      "or\n",
      "because\n",
      "as\n",
      "until\n",
      "while\n",
      "of\n",
      "at\n",
      "by\n",
      "for\n",
      "with\n",
      "about\n",
      "against\n",
      "between\n",
      "into\n",
      "through\n",
      "during\n",
      "before\n",
      "after\n",
      "above\n",
      "below\n",
      "to\n",
      "from\n",
      "up\n",
      "down\n",
      "in\n",
      "out\n",
      "on\n",
      "off\n",
      "over\n",
      "under\n",
      "again\n",
      "further\n",
      "then\n",
      "once\n",
      "here\n",
      "there\n",
      "when\n",
      "where\n",
      "why\n",
      "how\n",
      "all\n",
      "any\n",
      "both\n",
      "each\n",
      "few\n",
      "more\n",
      "most\n",
      "other\n",
      "some\n",
      "such\n",
      "no\n",
      "nor\n",
      "not\n",
      "only\n",
      "own\n",
      "same\n",
      "so\n",
      "than\n",
      "too\n",
      "very\n",
      "s\n",
      "t\n",
      "can\n",
      "will\n",
      "just\n",
      "don\n",
      "don't\n",
      "should\n",
      "should've\n",
      "now\n",
      "d\n",
      "ll\n",
      "m\n",
      "o\n",
      "re\n",
      "ve\n",
      "y\n",
      "ain\n",
      "aren\n",
      "aren't\n",
      "couldn\n",
      "couldn't\n",
      "didn\n",
      "didn't\n",
      "doesn\n",
      "doesn't\n",
      "hadn\n",
      "hadn't\n",
      "hasn\n",
      "hasn't\n",
      "haven\n",
      "haven't\n",
      "isn\n",
      "isn't\n",
      "ma\n",
      "mightn\n",
      "mightn't\n",
      "mustn\n",
      "mustn't\n",
      "needn\n",
      "needn't\n",
      "shan\n",
      "shan't\n",
      "shouldn\n",
      "shouldn't\n",
      "wasn\n",
      "wasn't\n",
      "weren\n",
      "weren't\n",
      "won\n",
      "won't\n",
      "wouldn\n",
      "wouldn't\n"
     ]
    }
   ],
   "source": [
    "stopwordsList = stopwords.words('english')\n",
    "for i in stopwordsList:\n",
    "    print(i)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering the string fron stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered List ['sentence', 'textual', 'unit', 'consisting', 'words', 'grammatically', 'linked', '.']\n",
      "Junk List ['a', 'is', 'a', 'of', 'that', 'are']\n"
     ]
    }
   ],
   "source": [
    "sampleString = \"A Sentence is a textual unit consisting of words that are grammatically linked.\"\n",
    "lowerString = sampleString.lower()\n",
    "wordToknized = word_tokenize(lowerString)\n",
    "filteredList = []\n",
    "junkList = []\n",
    "for i in wordToknized:\n",
    "    if i in stopwordsList:\n",
    "        junkList.append(i)\n",
    "    else:\n",
    "        filteredList.append(i)\n",
    "\n",
    "print('Filtered List', filteredList)\n",
    "print('Junk List', junkList)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing char from list: using String Translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Sentence is a textual unit consisting of words that are grammatically linked\n"
     ]
    }
   ],
   "source": [
    "sampleString1 = \"A Sentence is, a. textual- unit consisting_ of words that are grammatically linked.\"\n",
    "updatedList = sampleString1.translate({ord(i): None for i in \",._-\"})\n",
    "print(updatedList)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing char from list: using Regex library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Sentence is, a  textual  unit consisting_ of words that are grammatically linked \n"
     ]
    }
   ],
   "source": [
    "sampleString1 = \"A Sentence is, a. textual- unit consisting_ of words that are grammatically linked.\"\n",
    "print(re.sub(r'[.-]', ' ', sampleString1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(0, 1), match='A'>\n"
     ]
    }
   ],
   "source": [
    "# Searching text from string\n",
    "text = re.search('A', sampleString1)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(0, 1), match='A'>\n"
     ]
    }
   ],
   "source": [
    "# matching first word from string\n",
    "text = re.match('A', sampleString1)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'i', 'i', '#', '#', '#', 'i', '#', 'i']\n",
      "Hello guys, this is my first #tweet. Check thus @joy! #nlp #machine #learning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Searching all the chars from string\n",
    "tweet = \"Hello guys, this is my first #tweet. Check thus @joy! #nlp #machine #learning\"\n",
    "junk = re.findall('[#i]',tweet)\n",
    "print(junk)\n",
    "print(tweet)\n",
    "len(junk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello guys, this is my first #tweet. Check thus @joy! #nlp #machine #learning\n",
      "Hello guys, this is my first _tweet. Check thus @joy! _nlp _machine _learning\n"
     ]
    }
   ],
   "source": [
    "# Replacing the char in string\n",
    "re.sub('#','_', tweet)\n",
    "print(tweet)\n",
    "tweet = re.sub('#','_', tweet)\n",
    "print(tweet)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Special Seqeuences"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \\A retrun if it exist at the begining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Thenssn']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "text = \"Thenssn categorical cat hello mycat\"\n",
    "text1 = \"categorical cat hello mycat\"\n",
    "\n",
    "print(re.findall(r'\\AThe\\w+',text))\n",
    "print(re.findall(r'\\AThe',text1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \\b return letter available at begining or end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cat', 'cat']\n",
      "<re.Match object; span=(8, 11), match='cat'>\n",
      "['cat', 'cat']\n",
      "['cat']\n",
      "<callable_iterator object at 0x000001B4D8A439D0>\n",
      "<re.Match object; span=(8, 11), match='cat'>\n",
      "<re.Match object; span=(20, 23), match='cat'>\n"
     ]
    }
   ],
   "source": [
    "print(re.findall(r'\\bcat',text)) # Staring with cat word\n",
    "print(re.search(r'\\bcat', text)) \n",
    "print(re.findall(r'cat\\b',text)) # ending with cat word\n",
    "print(re.findall(r'\\bcat\\b',text)) #start and ends with cat\n",
    "print(re.finditer(r'\\bcat',text))\n",
    "\n",
    "for match in re.finditer(r'\\bcat', text):\n",
    "    # s = match.start()\n",
    "    # e = match.end()\n",
    "    print(match)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The']['The']"
     ]
    }
   ],
   "source": [
    "text = [\"The categorical cat hello mycat\",\"The new line\"]\n",
    "\n",
    "for i in text:\n",
    "    print(re.findall(r'\\AThe',i), end='')\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \\B return match not at the begining or end of the word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example 1 ['zi', 'zi']\n",
      "example 2 ['zi']\n"
     ]
    }
   ],
   "source": [
    "# zi should not be the start\n",
    "text1 = 'This is an amzing classroom, everyzi one speaks ENGLISH zizazo!'\n",
    "text2 = 'zi This is a good classroom, every one speaks ENGLISH zizxzid!'\n",
    "print('example 1', re.findall(r'\\Bzi', text1)) # zi should not be the start\n",
    "print('example 2', re.findall(r'\\Bzi', text2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example 1 None\n",
      "example 2 None\n"
     ]
    }
   ],
   "source": [
    "print('example 1', re.match(r'\\Bzi', text1))\n",
    "print('example 2', re.match(r'\\Bzi', text2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amzing\n",
      "stzing\n"
     ]
    }
   ],
   "source": [
    "text = 'This is an amzing classroom, every one stzing speaks ENGLISH. This is High_class!!'\n",
    "text = text.lower()\n",
    "wordToknized = word_tokenize(text)\n",
    "for i in wordToknized:\n",
    "    hh = re.findall(r'\\Bzi', i)\n",
    "    if len(hh) > 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example 1 ['amzing', 'stzing']\n"
     ]
    }
   ],
   "source": [
    "text = 'This is an amzing classroom, zi every one stzing speaks ENGLISH. This is High_class!!'\n",
    "print('example 1', re.findall(r'\\w+\\Bzi\\w+', text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextA ['class']\n",
      "TextB []\n"
     ]
    }
   ],
   "source": [
    "textA = 'This is an amzing classroom, zi every one stzing speaks ENGLISH. This is High_class!!'\n",
    "textB = 'This is an amzing classroom, zi every one stzing speaks ENGLISH. This is High-class!!'\n",
    "print('TextA', re.findall(r'\\Bclass', textA))\n",
    "print('TextB', re.findall(r'\\Bclass', textB))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextA ['class']\n"
     ]
    }
   ],
   "source": [
    "# class should not be the end\n",
    "textA = 'This is an amzing classroom, zi every one stzing speaks ENGLISH. This is High_class!!'\n",
    "print('TextA', re.findall(r'class\\B', textA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextA ['class']\n"
     ]
    }
   ],
   "source": [
    "# class should not be at start or end\n",
    "textA = 'This is an amzing rclassroom, zi every one stzing speaks ENGLISH. This is High_class!!'\n",
    "print('TextA', re.findall(r'\\Bclass\\B', textA))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \\d return digits 0-9 from string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextA ['2', '2', '2']\n"
     ]
    }
   ],
   "source": [
    "textA = 'This 222is an amzing rclassroom, zi every one stzing speaks ENGLISH. This is High_class!!'\n",
    "print('TextA', re.findall('\\d', textA))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \\D returns non digits from string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextA:  ['T', 'h', 'i', 's', ' ', 'i', 's', ' ', 'a', 'b', ' ', ' ', 'a', 'm', 'a', 'z', 'i', 'n', 'g', ' ', 'c', 'l', 'a', 's', 's', 'r', 'o', 'o', 'm', ',', ' ', ' ', 'e', 'v', 'e', 'r', 'y', ' ', 'o', 'n', 'e', ' ', 's', 'p', 'e', 'a', 'k', 's', ' ', 'E', 'N', 'G', 'L', 'I', 'S', 'H', ' ', '.', ' ', 'c', 'l', 'a', 's', 's', 'y', ' ', '!', '!']\n",
      "Merged List:  This is ab  amazing classroom,  every one speaks ENGLISH . classy !!\n"
     ]
    }
   ],
   "source": [
    "textA = 'This 2is ab 2 amazing classroom, 4 every one speaks ENGLISH 123. classy !!'\n",
    "new = re.findall('\\D', textA)\n",
    "kk =''.join(new) # converting list to string\n",
    "print('TextA: ', re.findall('\\D', textA))\n",
    "print('Merged List: ',kk)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \\s return all the shite spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']\n",
      "13\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "textA = 'This 2is ab 2 amazing classroom, 4 every one speaks ENGLISH 123. classy !!'\n",
    "print(re.findall(r'\\s',textA))              # return all the white spaces\n",
    "print(len(re.findall(r'\\s',textA)))         # return the count of white spaces\n",
    "print(len(re.findall(' ',textA)))           # return the count of white spaces"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \\S return without whitespaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T', 'h', 'i', 's', '2', 'i', 's', 'a', 'b', '2', 'a', 'm', 'a', 'z', 'i', 'n', 'g', 'c', 'l', 'a', 's', 's', 'r', 'o', 'o', 'm', ',', '4', 'e', 'v', 'e', 'r', 'y', 'o', 'n', 'e', 's', 'p', 'e', 'a', 'k', 's', 'E', 'N', 'G', 'L', 'I', 'S', 'H', '1', '2', '3', '.', 'c', 'l', 'a', 's', 's', 'y', '!', '!']\n",
      "61\n"
     ]
    }
   ],
   "source": [
    "textA = 'This 2is ab 2 amazing classroom, 4 every one speaks ENGLISH 123. classy !!'\n",
    "print(re.findall(r'\\S',textA))              # return without white spaces\n",
    "print(len(re.findall(r'\\S',textA)))         # return the count of non-white chars"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \\w any alphabetic, numeric and underscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T', 'h', 'i', 's', '2', 'i', 's', 'a', 'b', '2', 'a', 'm', 'a', 'z', 'i', 'n', 'g', 'c', 'l', 'a', 's', 's', 'r', 'o', 'o', 'm', '4', 'e', 'v', 'e', 'r', 'y', 'o', '_', 'n', 'e', 's', 'p', 'e', 'a', 'k', 's', 'E', 'N', 'G', 'L', 'I', 'S', 'H', '1', '2', '3', 'c', 'l', 'a', 's', 's', 'y']\n",
      "58\n"
     ]
    }
   ],
   "source": [
    "textA = 'This 2is ab 2 amazing classroom, 4 every o_ne speaks ENGLISH 123. classy !!'\n",
    "print(re.findall(r'\\w',textA))              # return only alphabets, numeric and underscore\n",
    "print(len(re.findall(r'\\w',textA)))         # return the count of non-white chars"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \\W no alphabets, numeric and underscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', ' ', ' ', ' ', ' ', ',', ' ', ' ', ' ', ' ', ' ', ' ', '.', ' ', ' ', '!', '!']\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "textA = 'This 2is ab 2 amazing classroom, 4 every o_ne speaks ENGLISH 123. classy !!'\n",
    "print(re.findall(r'\\W',textA))              # return only alphabets, numeric and underscore\n",
    "print(len(re.findall(r'\\W',textA)))         # return the count of non-white chars"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \\Z if specified is at the end of the string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['classy!!']\n"
     ]
    }
   ],
   "source": [
    "textA = 'This 2is ab 2 amazing classroom, 4 every o_ne speaks ENGLISH 123. classy!!'\n",
    "print(re.findall(r'\\w+!!\\Z',textA))              "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multiplechars [pqr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['m', 'n', 'o', 'o', 'm', 'o', 'n', 'p']\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "textA = 'This 2is ab 2 amazing classroom, 4 every o_ne speaks ENGLISH 123. classy!!'\n",
    "print(re.findall('[m-q]',textA)) \n",
    "print(len(re.findall('[m-q]',textA))) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### . (dot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['class', 'class']\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "textA = 'This 2is ab 2 amazing classroom, 4 every o_ne speaks ENGLISH 123. classy!!'\n",
    "print(re.findall('c...s',textA)) \n",
    "print(len(re.findall('c...s',textA))) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sy', 'sy']\n",
      "['sy']\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "textA = 'This 2is ab 2 amazing classroom, 4 every o_ne speaks ENGLISH 123 thisy\\nThis is classy'\n",
    "# print(re.findall('^Th',textA, re.M)) \n",
    "# print(re.findall('\\ATh',textA, re.M)) \n",
    "# print(len(re.findall('^Th',textA, re.M))) \n",
    "print(re.findall('sy$',textA, re.M)) \n",
    "print(re.findall('sy\\Z',textA, re.M)) \n",
    "print(len(re.findall('^Th',textA, re.M))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
