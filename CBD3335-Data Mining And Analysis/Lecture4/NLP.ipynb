{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        # In Class Activities May 30, 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = [\"  Interrobang. by Aishwarya Henriette      \", \"Parking And Going. By Karl Gautier\", \"     Today Is The night. By Jarek Prakash   \"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stripping whitespaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text:  ['  Interrobang. by Aishwarya Henriette      ', 'Parking And Going. By Karl Gautier', '     Today Is The night. By Jarek Prakash   ']\n",
      "After removing whitespaces:  ['Interrobang. by Aishwarya Henriette', 'Parking And Going. By Karl Gautier', 'Today Is The night. By Jarek Prakash']\n"
     ]
    }
   ],
   "source": [
    "strip_whitespaces = [string.strip() for string in text_data]\n",
    "print('Original Text: ', text_data)\n",
    "print('After removing whitespaces: ',strip_whitespaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 4, 6, 8, 10]\n"
     ]
    }
   ],
   "source": [
    "# Coding example for \n",
    "numbers = [1,2,3,4,5,6,7,8,9,10]\n",
    "even_Numbers = [x for x in numbers if x%2 == 0]\n",
    "print(even_Numbers)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replacing chars from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text:  ['Interrobang. by Aishwarya Henriette', 'Parking And Going. By Karl Gautier', 'Today Is The night. By Jarek Prakash']\n",
      "After removing periods:  ['Interrobang by Aishwarya Henriette', 'Parking And Going By Karl Gautier', 'Today Is The night By Jarek Prakash']\n"
     ]
    }
   ],
   "source": [
    "remove_periods = [string.replace('.','') for string in strip_whitespaces]\n",
    "print('Original Text: ', strip_whitespaces)\n",
    "print('After removing periods: ',remove_periods)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Capitalizing each word using function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text:  ['Interrobang by Aishwarya Henriette', 'Parking And Going By Karl Gautier', 'Today Is The night By Jarek Prakash']\n",
      "After capitalize operation:  ['INTERROBANG BY AISHWARYA HENRIETTE', 'PARKING AND GOING BY KARL GAUTIER', 'TODAY IS THE NIGHT BY JAREK PRAKASH']\n"
     ]
    }
   ],
   "source": [
    "def captializer(string):\n",
    "    return string.upper()\n",
    "capital_string = [captializer(string) for string in remove_periods]\n",
    "\n",
    "print('Original Text: ', remove_periods)\n",
    "print('After capitalize operation: ',capital_string)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing regex library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### replacing alphabets with X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text:  ['INTERROBANG BY AISHWARYA HENRIETTE', 'PARKING AND GOING BY KARL GAUTIER', 'TODAY IS THE NIGHT BY JAREK PRAKASH']\n",
      "After replacing with X:  ['XXXXXXXXXXX XX XXXXXXXXX XXXXXXXXX', 'XXXXXXX XXX XXXXX XX XXXX XXXXXXX', 'XXXXX XX XXX XXXXX XX XXXXX XXXXXXX']\n"
     ]
    }
   ],
   "source": [
    "def replace_chars_withX(string):\n",
    "    return re.sub(r'[a-zA-Z]','X', string)\n",
    "\n",
    "replaced_char_withX = [replace_chars_withX(x) for x in capital_string]\n",
    "print('Original Text: ', capital_string)\n",
    "print('After replacing with X: ',replaced_char_withX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi this is just an example nothing else'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'Hi! this is just an example, nothing else'\n",
    "re.sub(r'[^\\w\\s]','',text)      # \\w: AlphaNumeric characters, \\s: Whitespace, ^:except the following"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stopwords in language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "179\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "wordList = stopwords.words('english')\n",
    "print(type(wordList))\n",
    "print(len(wordList))\n",
    "print(wordList)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word Tokenize from NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'sentence', 'is', 'a', 'texual', 'unit', 'consisting', 'of', 'words', 'that', 'are', 'grammatically', 'linked', '.']\n"
     ]
    }
   ],
   "source": [
    "text = 'A sentence is a texual unit consisting of words that are grammatically linked.'\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokenzied_list = word_tokenize(text)\n",
    "print(tokenzied_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'sentence', 'texual', 'unit', 'consisting', 'words', 'grammatically', 'linked', '.']\n",
      "A sentence texual unit consisting words grammatically linked .\n"
     ]
    }
   ],
   "source": [
    "list_without_spotwords = []\n",
    "for x in tokenzied_list:\n",
    "    if x not in wordList:\n",
    "        list_without_spotwords.append(x)\n",
    "print(list_without_spotwords)\n",
    "\n",
    "final_string = ' '.join(list_without_spotwords)\n",
    "print(final_string)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sent Tokenize NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Lorem Ipsum is simply dummy text of the printing and typesetting industry.', \"Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book.\", 'It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged.']\n"
     ]
    }
   ],
   "source": [
    "sampleString = \"Lorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged.\"\n",
    "from nltk.tokenize import sent_tokenize\n",
    "sent_tokenzied_list = sent_tokenize(sampleString)\n",
    "print(sent_tokenzied_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python split function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Lorem', 'Ipsum', 'is', 'simply', 'dummy', 'text', 'of', 'the', 'printing', 'and', 'typesetting', 'industry.', 'Lorem', 'Ipsum', 'has', 'been', 'the', \"industry's\", 'standard', 'dummy', 'text', 'ever', 'since', 'the', '1500s,', 'when', 'an', 'unknown', 'printer', 'took', 'a', 'galley', 'of', 'type', 'and', 'scrambled', 'it', 'to', 'make', 'a', 'type', 'specimen', 'book.', 'It', 'has', 'survived', 'not', 'only', 'five', 'centuries,', 'but', 'also', 'the', 'leap', 'into', 'electronic', 'typesetting,', 'remaining', 'essentially', 'unchanged.']\n"
     ]
    }
   ],
   "source": [
    "print(sampleString.split())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Porter Stemming from NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scrambl\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "print(stemmer.stem('scrambled'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "print(lemmatizer.lemmatize('printing' ,pos='v'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag\n",
    "new = pos_tag(['ipsum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ipsum': 'NN'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict = dict(new)\n",
    "dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function nltk.tag.pos_tag(tokens, tagset=None, lang='eng')>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "es\n"
     ]
    }
   ],
   "source": [
    "from langdetect import detect\n",
    "from langcodes import Language\n",
    "\n",
    "language = detect('sentence')\n",
    "print(language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English\n"
     ]
    }
   ],
   "source": [
    "word = 'english'\n",
    "print(word.capitalize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fasttext'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mfasttext\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'fasttext'"
     ]
    }
   ],
   "source": [
    " import fasttext.util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en\n",
      "ru\n",
      "es\n",
      "af\n",
      "hi\n",
      "ja\n"
     ]
    }
   ],
   "source": [
    "# Python program to demonstrate\n",
    "# langdetect\n",
    "\n",
    "\n",
    "from langdetect import detect\n",
    "\n",
    "\n",
    "# Specifying the language for\n",
    "# detection\n",
    "print(detect(\"Geeksforgeeks is a computer science portal for geeks\"))\n",
    "print(detect(\"Geeksforgeeks - это компьютерный портал для гиков\"))\n",
    "print(detect(\"Geeksforgeeks es un portal informático para geeks\"))\n",
    "print(detect(\"Geeksforgeeks是面向极客的计算机科学门户\"))\n",
    "print(detect(\"Geeksforgeeks geeks के लिए एक कंप्यूटर विज्ञान पोर्टल है\"))\n",
    "print(detect(\"Geeksforgeeksは、ギーク向けのコンピューターサイエンスポータルです。\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 400: Bad Request",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m L:\t\n\u001b[0;32m     13\u001b[0m \tlang \u001b[39m=\u001b[39m TextBlob(i)\n\u001b[1;32m---> 14\u001b[0m \t\u001b[39mprint\u001b[39m(lang\u001b[39m.\u001b[39;49mdetect_language())\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\textblob\\blob.py:597\u001b[0m, in \u001b[0;36mBaseBlob.detect_language\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    572\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Detect the blob's language using the Google Translate API.\u001b[39;00m\n\u001b[0;32m    573\u001b[0m \n\u001b[0;32m    574\u001b[0m \u001b[39mRequires an internet connection.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[39m:rtype: str\u001b[39;00m\n\u001b[0;32m    591\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    592\u001b[0m warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    593\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mTextBlob.detext_translate is deprecated and will be removed in a future release. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    594\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mUse the official Google Translate API instead.\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m    595\u001b[0m     \u001b[39mDeprecationWarning\u001b[39;00m\n\u001b[0;32m    596\u001b[0m )\n\u001b[1;32m--> 597\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtranslator\u001b[39m.\u001b[39;49mdetect(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mraw)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\textblob\\translate.py:76\u001b[0m, in \u001b[0;36mTranslator.detect\u001b[1;34m(self, source, host, type_)\u001b[0m\n\u001b[0;32m     70\u001b[0m data \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mq\u001b[39m\u001b[39m\"\u001b[39m: source}\n\u001b[0;32m     71\u001b[0m url \u001b[39m=\u001b[39m \u001b[39mu\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{url}\u001b[39;00m\u001b[39m&sl=auto&tk=\u001b[39m\u001b[39m{tk}\u001b[39;00m\u001b[39m&client=\u001b[39m\u001b[39m{client}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m     72\u001b[0m     url\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39murl,\n\u001b[0;32m     73\u001b[0m     tk\u001b[39m=\u001b[39m_calculate_tk(source),\n\u001b[0;32m     74\u001b[0m     client\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mte\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     75\u001b[0m )\n\u001b[1;32m---> 76\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(url, host\u001b[39m=\u001b[39;49mhost, type_\u001b[39m=\u001b[39;49mtype_, data\u001b[39m=\u001b[39;49mdata)\n\u001b[0;32m     77\u001b[0m result, language \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mloads(response)\n\u001b[0;32m     78\u001b[0m \u001b[39mreturn\u001b[39;00m language\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\textblob\\translate.py:96\u001b[0m, in \u001b[0;36mTranslator._request\u001b[1;34m(self, url, host, type_, data)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[39mif\u001b[39;00m host \u001b[39mor\u001b[39;00m type_:\n\u001b[0;32m     95\u001b[0m     req\u001b[39m.\u001b[39mset_proxy(host\u001b[39m=\u001b[39mhost, \u001b[39mtype\u001b[39m\u001b[39m=\u001b[39mtype_)\n\u001b[1;32m---> 96\u001b[0m resp \u001b[39m=\u001b[39m request\u001b[39m.\u001b[39;49murlopen(req)\n\u001b[0;32m     97\u001b[0m content \u001b[39m=\u001b[39m resp\u001b[39m.\u001b[39mread()\n\u001b[0;32m     98\u001b[0m \u001b[39mreturn\u001b[39;00m content\u001b[39m.\u001b[39mdecode(\u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\urllib\\request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    215\u001b[0m     opener \u001b[39m=\u001b[39m _opener\n\u001b[1;32m--> 216\u001b[0m \u001b[39mreturn\u001b[39;00m opener\u001b[39m.\u001b[39;49mopen(url, data, timeout)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\urllib\\request.py:525\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    523\u001b[0m \u001b[39mfor\u001b[39;00m processor \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_response\u001b[39m.\u001b[39mget(protocol, []):\n\u001b[0;32m    524\u001b[0m     meth \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(processor, meth_name)\n\u001b[1;32m--> 525\u001b[0m     response \u001b[39m=\u001b[39m meth(req, response)\n\u001b[0;32m    527\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\urllib\\request.py:634\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[39m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[0;32m    632\u001b[0m \u001b[39m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[0;32m    633\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m code \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m):\n\u001b[1;32m--> 634\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparent\u001b[39m.\u001b[39;49merror(\n\u001b[0;32m    635\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39mhttp\u001b[39;49m\u001b[39m'\u001b[39;49m, request, response, code, msg, hdrs)\n\u001b[0;32m    637\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\urllib\\request.py:563\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[39mif\u001b[39;00m http_err:\n\u001b[0;32m    562\u001b[0m     args \u001b[39m=\u001b[39m (\u001b[39mdict\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdefault\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mhttp_error_default\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m+\u001b[39m orig_args\n\u001b[1;32m--> 563\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_chain(\u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\urllib\\request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[39mfor\u001b[39;00m handler \u001b[39min\u001b[39;00m handlers:\n\u001b[0;32m    495\u001b[0m     func \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 496\u001b[0m     result \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs)\n\u001b[0;32m    497\u001b[0m     \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    498\u001b[0m         \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\urllib\\request.py:643\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[1;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[0;32m    642\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhttp_error_default\u001b[39m(\u001b[39mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[1;32m--> 643\u001b[0m     \u001b[39mraise\u001b[39;00m HTTPError(req\u001b[39m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[1;31mHTTPError\u001b[0m: HTTP Error 400: Bad Request"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "\n",
    "L = [\"Geeksforgeeks is a computer science portal for geeks\",\n",
    "\t\"Geeksforgeeks - это компьютерный портал для гиков\",\n",
    "\t\"Geeksforgeeks es un portal informático para geeks\",\n",
    "\t\"Geeksforgeeks是面向极客的计算机科学门户\",\n",
    "\t\"Geeksforgeeks geeks के लिए एक कंप्यूटर विज्ञान पोर्टल है\",\n",
    "\t\"Geeksforgeeksは、ギーク向けのコンピューターサイエンスポータルです。\",\n",
    "\t]\n",
    "\n",
    "for i in L:\t\n",
    "\tlang = TextBlob(i)\n",
    "\tprint(lang.detect_language())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'it'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import langid\n",
    "\n",
    "langid.classify('English')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "LanguageTagError",
     "evalue": "Expected a language code, got 'english'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLanguageTagError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangcodes\u001b[39;00m \u001b[39mimport\u001b[39;00m Language\n\u001b[1;32m----> 2\u001b[0m Language\u001b[39m.\u001b[39;49mget(\u001b[39m'\u001b[39;49m\u001b[39menglish\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39mdisplay_name()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\langcodes\\__init__.py:304\u001b[0m, in \u001b[0;36mLanguage.get\u001b[1;34m(tag, normalize)\u001b[0m\n\u001b[0;32m    301\u001b[0m \u001b[39mif\u001b[39;00m normalize \u001b[39mand\u001b[39;00m tag_lower \u001b[39min\u001b[39;00m LANGUAGE_REPLACEMENTS:\n\u001b[0;32m    302\u001b[0m     tag \u001b[39m=\u001b[39m LANGUAGE_REPLACEMENTS[tag_lower]\n\u001b[1;32m--> 304\u001b[0m components \u001b[39m=\u001b[39m parse_tag(tag)\n\u001b[0;32m    306\u001b[0m \u001b[39mfor\u001b[39;00m typ, value \u001b[39min\u001b[39;00m components:\n\u001b[0;32m    307\u001b[0m     \u001b[39mif\u001b[39;00m typ \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mextlang\u001b[39m\u001b[39m'\u001b[39m \u001b[39mand\u001b[39;00m normalize \u001b[39mand\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mlanguage\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m data:\n\u001b[0;32m    308\u001b[0m         \u001b[39m# smash extlangs when possible\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\langcodes\\tag_parser.py:212\u001b[0m, in \u001b[0;36mparse_tag\u001b[1;34m(tag)\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[39mreturn\u001b[39;00m [(\u001b[39m'\u001b[39m\u001b[39mlanguage\u001b[39m\u001b[39m'\u001b[39m, subtags[\u001b[39m0\u001b[39m])] \u001b[39m+\u001b[39m parse_subtags(subtags[\u001b[39m1\u001b[39m:])\n\u001b[0;32m    211\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 212\u001b[0m     subtag_error(subtags[\u001b[39m0\u001b[39;49m], \u001b[39m'\u001b[39;49m\u001b[39ma language code\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\langcodes\\tag_parser.py:422\u001b[0m, in \u001b[0;36msubtag_error\u001b[1;34m(subtag, expected)\u001b[0m\n\u001b[0;32m    416\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msubtag_error\u001b[39m(subtag, expected\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39ma valid subtag\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m    417\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    418\u001b[0m \u001b[39m    Try to output a reasonably helpful error message based on our state of\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[39m    parsing. Most of this code is about how to list, in English, the kinds\u001b[39;00m\n\u001b[0;32m    420\u001b[0m \u001b[39m    of things we were expecting to find.\u001b[39;00m\n\u001b[0;32m    421\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 422\u001b[0m     \u001b[39mraise\u001b[39;00m LanguageTagError(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExpected \u001b[39m\u001b[39m{\u001b[39;00mexpected\u001b[39m}\u001b[39;00m\u001b[39m, got \u001b[39m\u001b[39m{\u001b[39;00msubtag\u001b[39m!r}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mLanguageTagError\u001b[0m: Expected a language code, got 'english'"
     ]
    }
   ],
   "source": [
    "\n",
    "from langcodes import Language\n",
    "Language.get('english').display_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
