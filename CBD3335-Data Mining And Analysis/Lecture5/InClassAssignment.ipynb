{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = \"Feature Extraction aims to reduce the number of features in a dataset by creating new features from the existing ones (and then discarding the original features). These new reduced set of features should then be able to summarize most of the information contained in the original set of features!!!. In this way, a summarised version of the original features can be created from a combination of the original set!!!Another commonly used technique to reduce the number of feature in a dataset is Feature Selection! The difference between Feature Selection and/or Feature Extraction is that feature selection aims instead to $ rank the importance of the existing features in the dataset and discard less important ones (no new features are created)?!. If you are interested in finding out more about Feature Selection, you can find more information about it in my previous article.In this article, I will walk you through how to apply Feature Extraction techniques using the Kaggle Mushroom Classification Dataset as an example??? Our objective will be to try to predict if a Mushroom is poisonous or not by looking at the given features. All the code used in this post (and more!) is available on Kaggle and on my GitHub Account.\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  ***Remove stopword and punctuation***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original String:  feature extraction aims reduce number features dataset creating new features existing ones ( discarding original features ) . new reduced set features able summarize information contained original set features ! ! ! . way , summarised version original features created combination original set ! ! ! another commonly used technique reduce number feature dataset feature selection ! difference feature selection and/or feature extraction feature selection aims instead $ rank importance existing features dataset discard less important ones ( new features created ) ? ! . interested finding feature selection , find information previous article.in article , walk apply feature extraction techniques using kaggle mushroom classification dataset example ? ? ? objective try predict mushroom poisonous looking given features . code used post ( ! ) available kaggle github account .\n",
      "Modified String:  feature extraction aims reduce number features dataset creating new features existing ones discarding original features new reduced set features able summarize information contained original set features way summarised version original features created combination original set another commonly used technique reduce number feature dataset feature selection difference feature selection andor feature extraction feature selection aims instead rank importance existing features dataset discard less important ones new features created interested finding feature selection find information previous articlein article walk apply feature extraction techniques using kaggle mushroom classification dataset example objective try predict mushroom poisonous looking given features code used post available kaggle github account\n"
     ]
    }
   ],
   "source": [
    "tokenlist = word_tokenize(text_data.lower())\n",
    "stopwordsList = stopwords.words('english')\n",
    "finalList = []\n",
    "\n",
    "# removing Stopwords from the string\n",
    "for x in tokenlist:\n",
    "    if x not in stopwordsList:\n",
    "        finalList.append(x)\n",
    "\n",
    "stringWithoutStopwords = \" \".join(finalList)\n",
    "print('Original String: ',stringWithoutStopwords)\n",
    "\n",
    "# removing Punctuations from the string\n",
    "punc = \"!()-[]{};:'\\\"\\,<>./?@#$%^&*_~\"\n",
    "finalString = ''\n",
    "for ele in stringWithoutStopwords:\n",
    "    if ele in punc:\n",
    "        stringWithoutStopwords = stringWithoutStopwords.replace(ele, \"\")\n",
    "\n",
    "stringWithoutStopwords= \" \".join(stringWithoutStopwords.split())\n",
    "print('Modified String: ',stringWithoutStopwords)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  ***Stemming & lemmetization***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original String:  feature extraction aims reduce number features dataset creating new features existing ones discarding original features new reduced set features able summarize information contained original set features way summarised version original features created combination original set another commonly used technique reduce number feature dataset feature selection difference feature selection andor feature extraction feature selection aims instead rank importance existing features dataset discard less important ones new features created interested finding feature selection find information previous articlein article walk apply feature extraction techniques using kaggle mushroom classification dataset example objective try predict mushroom poisonous looking given features code used post available kaggle github account\n",
      "Modified String:  featur extract aim reduc number featur dataset creat new featur exist one discard origin featur new reduc set featur abl summar inform contain origin set featur way summaris version origin featur creat combin origin set anoth commonli use techniqu reduc number featur dataset featur select differ featur select andor featur extract featur select aim instead rank import exist featur dataset discard less import one new featur creat interest find featur select find inform previou articlein articl walk appli featur extract techniqu use kaggl mushroom classif dataset exampl object tri predict mushroom poison look given featur code use post avail kaggl github account\n"
     ]
    }
   ],
   "source": [
    "# Performing Stemmization operation\n",
    "porter = PorterStemmer()\n",
    "StemmedString = []\n",
    "for x in stringWithoutStopwords.split(' '):\n",
    "    y = porter.stem(x)\n",
    "    StemmedString.append(y)\n",
    "\n",
    "StemmedString = ' '.join(StemmedString)\n",
    "print('Original String: ',stringWithoutStopwords)\n",
    "print('Modified String: ',StemmedString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original String:  feature extraction aims reduce number features dataset creating new features existing ones discarding original features new reduced set features able summarize information contained original set features way summarised version original features created combination original set another commonly used technique reduce number feature dataset feature selection difference feature selection andor feature extraction feature selection aims instead rank importance existing features dataset discard less important ones new features created interested finding feature selection find information previous articlein article walk apply feature extraction techniques using kaggle mushroom classification dataset example objective try predict mushroom poisonous looking given features code used post available kaggle github account\n",
      "Modified String:  feature extraction aim reduce number feature dataset create new feature exist ones discard original feature new reduce set feature able summarize information contain original set feature way summarise version original feature create combination original set another commonly use technique reduce number feature dataset feature selection difference feature selection andor feature extraction feature selection aim instead rank importance exist feature dataset discard less important ones new feature create interest find feature selection find information previous articlein article walk apply feature extraction techniques use kaggle mushroom classification dataset example objective try predict mushroom poisonous look give feature code use post available kaggle github account\n"
     ]
    }
   ],
   "source": [
    "# Performing Lemmetization operation\n",
    "lem = WordNetLemmatizer()\n",
    "LemmetizedString = []\n",
    "for x in stringWithoutStopwords.split(' '):\n",
    "    y = lem.lemmatize(x, pos='v')\n",
    "    LemmetizedString.append(y)\n",
    "LemmetizedString = ' '.join(LemmetizedString)\n",
    "print('Original String: ',stringWithoutStopwords)\n",
    "print('Modified String: ',LemmetizedString)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  ***POS***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parts of speech : [('feature', 'NN'), ('extraction', 'NN'), ('aims', 'VBZ'), ('to', 'TO'), ('reduce', 'VB'), ('the', 'DT'), ('number', 'NN'), ('of', 'IN'), ('features', 'NNS'), ('in', 'IN'), ('a', 'DT'), ('dataset', 'NN'), ('by', 'IN'), ('creating', 'VBG'), ('new', 'JJ'), ('features', 'NNS'), ('from', 'IN'), ('the', 'DT'), ('existing', 'VBG'), ('ones', 'NNS'), ('(', '('), ('and', 'CC'), ('then', 'RB'), ('discarding', 'VBG'), ('the', 'DT'), ('original', 'JJ'), ('features', 'NNS'), (')', ')'), ('.', '.'), ('these', 'DT'), ('new', 'JJ'), ('reduced', 'VBD'), ('set', 'NN'), ('of', 'IN'), ('features', 'NNS'), ('should', 'MD'), ('then', 'RB'), ('be', 'VB'), ('able', 'JJ'), ('to', 'TO'), ('summarize', 'VB'), ('most', 'JJS'), ('of', 'IN'), ('the', 'DT'), ('information', 'NN'), ('contained', 'VBN'), ('in', 'IN'), ('the', 'DT'), ('original', 'JJ'), ('set', 'NN'), ('of', 'IN'), ('features', 'NNS'), ('!', '.'), ('!', '.'), ('!', '.'), ('.', '.'), ('in', 'IN'), ('this', 'DT'), ('way', 'NN'), (',', ','), ('a', 'DT'), ('summarised', 'JJ'), ('version', 'NN'), ('of', 'IN'), ('the', 'DT'), ('original', 'JJ'), ('features', 'NNS'), ('can', 'MD'), ('be', 'VB'), ('created', 'VBN'), ('from', 'IN'), ('a', 'DT'), ('combination', 'NN'), ('of', 'IN'), ('the', 'DT'), ('original', 'JJ'), ('set', 'NN'), ('!', '.'), ('!', '.'), ('!', '.'), ('another', 'DT'), ('commonly', 'RB'), ('used', 'VBN'), ('technique', 'NN'), ('to', 'TO'), ('reduce', 'VB'), ('the', 'DT'), ('number', 'NN'), ('of', 'IN'), ('feature', 'NN'), ('in', 'IN'), ('a', 'DT'), ('dataset', 'NN'), ('is', 'VBZ'), ('feature', 'JJ'), ('selection', 'NN'), ('!', '.'), ('the', 'DT'), ('difference', 'NN'), ('between', 'IN'), ('feature', 'NN'), ('selection', 'NN'), ('and/or', 'IN'), ('feature', 'NN'), ('extraction', 'NN'), ('is', 'VBZ'), ('that', 'IN'), ('feature', 'NN'), ('selection', 'NN'), ('aims', 'VBZ'), ('instead', 'RB'), ('to', 'TO'), ('$', '$'), ('rank', 'VB'), ('the', 'DT'), ('importance', 'NN'), ('of', 'IN'), ('the', 'DT'), ('existing', 'VBG'), ('features', 'NNS'), ('in', 'IN'), ('the', 'DT'), ('dataset', 'NN'), ('and', 'CC'), ('discard', 'NN'), ('less', 'RBR'), ('important', 'JJ'), ('ones', 'NNS'), ('(', '('), ('no', 'DT'), ('new', 'JJ'), ('features', 'NNS'), ('are', 'VBP'), ('created', 'VBN'), (')', ')'), ('?', '.'), ('!', '.'), ('.', '.'), ('if', 'IN'), ('you', 'PRP'), ('are', 'VBP'), ('interested', 'JJ'), ('in', 'IN'), ('finding', 'VBG'), ('out', 'RP'), ('more', 'RBR'), ('about', 'IN'), ('feature', 'NN'), ('selection', 'NN'), (',', ','), ('you', 'PRP'), ('can', 'MD'), ('find', 'VB'), ('more', 'JJR'), ('information', 'NN'), ('about', 'IN'), ('it', 'PRP'), ('in', 'IN'), ('my', 'PRP$'), ('previous', 'JJ'), ('article.in', 'NN'), ('this', 'DT'), ('article', 'NN'), (',', ','), ('i', 'NN'), ('will', 'MD'), ('walk', 'VB'), ('you', 'PRP'), ('through', 'IN'), ('how', 'WRB'), ('to', 'TO'), ('apply', 'VB'), ('feature', 'JJ'), ('extraction', 'NN'), ('techniques', 'NNS'), ('using', 'VBG'), ('the', 'DT'), ('kaggle', 'NN'), ('mushroom', 'NN'), ('classification', 'NN'), ('dataset', 'NN'), ('as', 'IN'), ('an', 'DT'), ('example', 'NN'), ('?', '.'), ('?', '.'), ('?', '.'), ('our', 'PRP$'), ('objective', 'NN'), ('will', 'MD'), ('be', 'VB'), ('to', 'TO'), ('try', 'VB'), ('to', 'TO'), ('predict', 'VB'), ('if', 'IN'), ('a', 'DT'), ('mushroom', 'NN'), ('is', 'VBZ'), ('poisonous', 'JJ'), ('or', 'CC'), ('not', 'RB'), ('by', 'IN'), ('looking', 'VBG'), ('at', 'IN'), ('the', 'DT'), ('given', 'VBN'), ('features', 'NNS'), ('.', '.'), ('all', 'PDT'), ('the', 'DT'), ('code', 'NN'), ('used', 'VBN'), ('in', 'IN'), ('this', 'DT'), ('post', 'NN'), ('(', '('), ('and', 'CC'), ('more', 'JJR'), ('!', '.'), (')', ')'), ('is', 'VBZ'), ('available', 'JJ'), ('on', 'IN'), ('kaggle', 'NN'), ('and', 'CC'), ('on', 'IN'), ('my', 'PRP$'), ('github', 'NN'), ('account', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "# finding POS of each word\n",
    "print('Parts of speech :', nltk.pos_tag(tokenlist) )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  ***Bag of Words***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = np.array([\"Feature Extraction aims to reduce the number of features in a dataset by creating new features from the existing ones (and then discarding the original features). These new reduced set of features should then be able to summarize most of the information contained in the original set of features!!!. In this way, a summarised version of the original features can be created from a combination of the original set!!!\",\n",
    "                      \"Another commonly used technique to reduce the number of feature in a dataset is Feature Selection! The difference between Feature Selection and/or Feature Extraction is that feature selection aims instead to $ rank the importance of the existing features in the dataset and discard less important ones (no new features are created)?!. If you are interested in finding out more about Feature Selection, you can find more information about it in my previous article.\",\n",
    "                      \"In this article, I will walk you through how to apply Feature Extraction techniques using the Kaggle Mushroom Classification Dataset as an example??? Our objective will be to try to predict if a Mushroom is poisonous or not by looking at the given features. All the code used in this post (and more!) is available on Kaggle and on my GitHub Account.\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>about</th>\n",
       "      <th>account</th>\n",
       "      <th>aims</th>\n",
       "      <th>all</th>\n",
       "      <th>an</th>\n",
       "      <th>and</th>\n",
       "      <th>another</th>\n",
       "      <th>apply</th>\n",
       "      <th>are</th>\n",
       "      <th>...</th>\n",
       "      <th>through</th>\n",
       "      <th>to</th>\n",
       "      <th>try</th>\n",
       "      <th>used</th>\n",
       "      <th>using</th>\n",
       "      <th>version</th>\n",
       "      <th>walk</th>\n",
       "      <th>way</th>\n",
       "      <th>will</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   able  about  account  aims  all  an  and  another  apply  are  ...  \\\n",
       "0     1      0        0     1    0   0    1        0      0    0  ...   \n",
       "1     0      2        0     1    0   0    2        1      0    2  ...   \n",
       "2     0      0        1     0    1   1    2        0      1    0  ...   \n",
       "\n",
       "   through  to  try  used  using  version  walk  way  will  you  \n",
       "0        0   2    0     0      0        1     0    1     0    0  \n",
       "1        0   2    0     1      0        0     0    0     0    2  \n",
       "2        1   3    1     1      1        0     1    0     2    1  \n",
       "\n",
       "[3 rows x 97 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bag of Words \n",
    "Count = CountVectorizer()\n",
    "bag_of_words = Count.fit_transform(text_data)\n",
    "pd.DataFrame(bag_of_words.toarray(), columns = Count.get_feature_names_out())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  ***TFIDF***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>about</th>\n",
       "      <th>account</th>\n",
       "      <th>aims</th>\n",
       "      <th>all</th>\n",
       "      <th>an</th>\n",
       "      <th>and</th>\n",
       "      <th>another</th>\n",
       "      <th>apply</th>\n",
       "      <th>are</th>\n",
       "      <th>...</th>\n",
       "      <th>through</th>\n",
       "      <th>to</th>\n",
       "      <th>try</th>\n",
       "      <th>used</th>\n",
       "      <th>using</th>\n",
       "      <th>version</th>\n",
       "      <th>walk</th>\n",
       "      <th>way</th>\n",
       "      <th>will</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.09415</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071603</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055606</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111213</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.09415</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.09415</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.207232</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078803</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.122395</td>\n",
       "      <td>0.103616</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.207232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.122395</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078803</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.157606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.127726</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.127726</td>\n",
       "      <td>0.127726</td>\n",
       "      <td>0.150874</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.127726</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.127726</td>\n",
       "      <td>0.226311</td>\n",
       "      <td>0.127726</td>\n",
       "      <td>0.097139</td>\n",
       "      <td>0.127726</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.127726</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.255451</td>\n",
       "      <td>0.097139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      able     about   account      aims       all        an       and  \\\n",
       "0  0.09415  0.000000  0.000000  0.071603  0.000000  0.000000  0.055606   \n",
       "1  0.00000  0.207232  0.000000  0.078803  0.000000  0.000000  0.122395   \n",
       "2  0.00000  0.000000  0.127726  0.000000  0.127726  0.127726  0.150874   \n",
       "\n",
       "    another     apply       are  ...   through        to       try      used  \\\n",
       "0  0.000000  0.000000  0.000000  ...  0.000000  0.111213  0.000000  0.000000   \n",
       "1  0.103616  0.000000  0.207232  ...  0.000000  0.122395  0.000000  0.078803   \n",
       "2  0.000000  0.127726  0.000000  ...  0.127726  0.226311  0.127726  0.097139   \n",
       "\n",
       "      using  version      walk      way      will       you  \n",
       "0  0.000000  0.09415  0.000000  0.09415  0.000000  0.000000  \n",
       "1  0.000000  0.00000  0.000000  0.00000  0.000000  0.157606  \n",
       "2  0.127726  0.00000  0.127726  0.00000  0.255451  0.097139  \n",
       "\n",
       "[3 rows x 97 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TFIDF vectorization\n",
    "tfidf = TfidfVectorizer()\n",
    "feature_matrix = tfidf.fit_transform(text_data)\n",
    "pd.DataFrame(feature_matrix.toarray(), columns = Count.get_feature_names_out())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
