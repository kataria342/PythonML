{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The detected language is: en\n",
      "ola, how are you?\n",
      "ola : en\n",
      ", : en\n",
      "how : en\n",
      "are : en\n",
      "you : en\n",
      "? : en\n",
      "Non-English words: []\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the language model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def detect_language(text):\n",
    "    doc = nlp(text)\n",
    "    language_code = doc.lang_\n",
    "    return language_code\n",
    "\n",
    "def detect_non_english_words(text):\n",
    "    doc = nlp(text)\n",
    "    non_english_words = []\n",
    "    print(doc)\n",
    "\n",
    "    for token in doc:\n",
    "        print(token,':',token.lang_)\n",
    "        \n",
    "        if not token.is_alpha:\n",
    "            continue  # Skip if the token is not alphabetic\n",
    "\n",
    "        if token.lang_ != 'en':\n",
    "            non_english_words.append(token.text)\n",
    "\n",
    "    return non_english_words\n",
    "\n",
    "\n",
    "text = \"ola, how are you?\"\n",
    "\n",
    "language = detect_language(text)\n",
    "print(f\"The detected language is: {language}\")\n",
    "\n",
    "non_english_words = detect_non_english_words(text)\n",
    "print(\"Non-English words:\", non_english_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one hundred and twenty-three\n"
     ]
    }
   ],
   "source": [
    "from num2words import num2words\n",
    "\n",
    "number = 123\n",
    "text = num2words(number)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "犬 árbol 世界 你好 monde chien árbol كلب 树 cão bonjour mundo мир hund привет hola cão perro bonjour albero ciao árvore albero árbol chien árvore 你好 baum cão mundo قطة cane 你好 hund hola شجرة arbre мир welt кошка\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Define lists of words from different languages\n",
    "word_lists = {\n",
    "    'english': ['hello', 'world', 'cat', 'dog', 'tree'],\n",
    "    'spanish': ['hola', 'mundo', 'gato', 'perro', 'árbol'],\n",
    "    'french': ['bonjour', 'monde', 'chat', 'chien', 'arbre'],\n",
    "    'german': ['hallo', 'welt', 'katze', 'hund', 'baum'],\n",
    "    'italian': ['ciao', 'mondo', 'gatto', 'cane', 'albero'],\n",
    "    'portuguese': ['olá', 'mundo', 'gato', 'cão', 'árvore'],\n",
    "    'japanese': ['こんにちは', '世界', '猫', '犬', '木'],\n",
    "    'chinese': ['你好', '世界', '猫', '狗', '树'],\n",
    "    'russian': ['привет', 'мир', 'кошка', 'собака', 'дерево'],\n",
    "    'arabic': ['مرحبا', 'عالم', 'قطة', 'كلب', 'شجرة']\n",
    "}\n",
    "\n",
    "# Generate the sentence\n",
    "sentence = []\n",
    "for _ in range(40):\n",
    "    language = random.choice(list(word_lists.keys()))\n",
    "    word = random.choice(word_lists[language])\n",
    "    sentence.append(word)\n",
    "\n",
    "# Convert the sentence list into a string\n",
    "sentence = \" \".join(sentence)\n",
    "print(sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
